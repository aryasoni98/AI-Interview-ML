{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition - Signal Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to set up all speech emotion recognition preprocessing for the time distributed ConvNet. \n",
    "\n",
    "The data set used for training is the **RAVDESS** data set : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391\n",
    "\n",
    "The signal preprocessing include :\n",
    "- Signal discretization\n",
    "- Audio data augmentation\n",
    "- Log-mel-spectrogram extraction\n",
    "- Time distributed framing\n",
    "- Build train and test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. General import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (0.9.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (0.4.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (61.2.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (0.38.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /Users/aryasoni/opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:29:23.010808Z",
     "start_time": "2019-05-21T16:29:19.571354Z"
    }
   },
   "outputs": [],
   "source": [
    "### General imports ###\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Graph imports ###\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "### Audio import ###\n",
    "import librosa\n",
    "import IPython\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:38:44.580314Z",
     "start_time": "2018-12-04T16:38:44.560062Z"
    }
   },
   "source": [
    "## III. Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:29:23.018183Z",
     "start_time": "2019-05-21T16:29:23.013273Z"
    }
   },
   "outputs": [],
   "source": [
    "# RAVDESS Database\n",
    "label_dict_ravdess = {'02': 'NEU', '03':'HAP', '04':'SAD', '05':'ANG', '06':'FEA', '07':'DIS', '08':'SUR'}\n",
    "\n",
    "# Set audio files labels\n",
    "def set_label_ravdess(audio_file, gender_differentiation):\n",
    "    label = label_dict_ravdess.get(audio_file[6:-16])\n",
    "    if gender_differentiation == True:\n",
    "        if int(audio_file[18:-4])%2 == 0: # Female\n",
    "            label = 'f_' + label\n",
    "        if int(audio_file[18:-4])%2 == 1: # Male\n",
    "            label = 'm_' + label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Import audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:42.869915Z",
     "start_time": "2019-05-21T16:29:23.020121Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Data: START\n",
      "Import Data: END \n",
      "\n",
      "Number of audio files imported: 0\n"
     ]
    }
   ],
   "source": [
    "# Start feature extraction\n",
    "print(\"Import Data: START\")\n",
    "\n",
    "# Audio file path and names\n",
    "file_path = '../../Dataset/RAVDESS/'\n",
    "file_names = os.listdir(file_path)\n",
    "\n",
    "# Initialize features and labels list\n",
    "signal = []\n",
    "labels = []\n",
    "\n",
    "# Sample rate (16.0 kHz)\n",
    "sample_rate = 16000     \n",
    "\n",
    "# Max pad lenght (3.0 sec)\n",
    "max_pad_len = 49100\n",
    "\n",
    "# Compute spectogram for all audio file\n",
    "for audio_index, audio_file in enumerate(file_names):\n",
    "    \n",
    "    if audio_file[6:-16] in list(label_dict_ravdess.keys()):\n",
    "        \n",
    "        # Read audio file\n",
    "        y, sr = librosa.core.load(file_path + audio_file, sr=sample_rate, offset=0.5)\n",
    "        \n",
    "        # Z-normalization\n",
    "        y = zscore(y)\n",
    "        \n",
    "        # Padding or truncated signal \n",
    "        if len(y) < max_pad_len:    \n",
    "            y_padded = np.zeros(max_pad_len)\n",
    "            y_padded[:len(y)] = y\n",
    "            y = y_padded\n",
    "        elif len(y) > max_pad_len:\n",
    "            y = np.asarray(y[:max_pad_len])\n",
    "        \n",
    "        # Add to signal list\n",
    "        signal.append(y)\n",
    "        \n",
    "        # Set label\n",
    "        labels.append(set_label_ravdess(audio_file, False))\n",
    "\n",
    "        # Print running...\n",
    "        if (audio_index % 100 == 0):\n",
    "            print(\"Import Data: RUNNING ... {} files\".format(audio_index))\n",
    "        \n",
    "# Cast labels to array\n",
    "labels = np.asarray(labels).ravel()\n",
    "\n",
    "# Stop feature extraction\n",
    "print(\"Import Data: END \\n\")\n",
    "print(\"Number of audio files imported: {}\".format(labels.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:43.040298Z",
     "start_time": "2019-05-21T16:31:42.873046Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Select one random audio file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m random_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m random_label \u001b[38;5;241m=\u001b[39m labels[random_idx]\n\u001b[1;32m      4\u001b[0m random_signal \u001b[38;5;241m=\u001b[39m signal[random_idx]\n",
      "File \u001b[0;32mmtrand.pyx:748\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1247\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "# Select one random audio file\n",
    "random_idx = np.random.randint(len(labels))\n",
    "random_label = labels[random_idx]\n",
    "random_signal = signal[random_idx]\n",
    "random_filename = file_names[random_idx]\n",
    "\n",
    "# Plot signal wave\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(len(random_signal))/float(sample_rate), random_signal)\n",
    "plt.xlim((np.arange(len(random_signal))/float(sample_rate))[0], (np.arange(len(random_signal))/float(sample_rate))[-1])\n",
    "plt.xlabel('Time (s)', fontsize=16)\n",
    "plt.ylabel('Amplitude (dB)', fontsize=16)\n",
    "plt.title(\"Signal wave of file '{}' with label {}\".format(random_filename, random_label), fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# Play audio file\n",
    "print(\"Audio file '{}':\".format(random_filename))\n",
    "Audio(random_signal, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Audio data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:43.048012Z",
     "start_time": "2019-05-21T16:31:43.043368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of augmented data\n",
    "nb_augmented = 2\n",
    "\n",
    "# Function to add noise to a signals with a desired Signal Noise ratio (SNR)\n",
    "def noisy_signal(signal, snr_low=15, snr_high=30, nb_augmented=2):\n",
    "    \n",
    "    # Signal length\n",
    "    signal_len = len(signal)\n",
    "\n",
    "    # Generate White noise\n",
    "    noise = np.random.normal(size=(nb_augmented, signal_len))\n",
    "    \n",
    "    # Compute signal and noise power\n",
    "    s_power = np.sum((signal / (2.0 ** 15)) ** 2) / signal_len\n",
    "    n_power = np.sum((noise / (2.0 ** 15)) ** 2, axis=1) / signal_len\n",
    "    \n",
    "    # Random SNR: Uniform [15, 30]\n",
    "    snr = np.random.randint(snr_low, snr_high)\n",
    "    \n",
    "    # Compute K coeff for each noise\n",
    "    K = np.sqrt((s_power / n_power) * 10 ** (- snr / 10))\n",
    "    K = np.ones((signal_len, nb_augmented)) * K\n",
    "    \n",
    "    # Generate noisy signal\n",
    "    return signal + K.T * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:48.009729Z",
     "start_time": "2019-05-21T16:31:43.049711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation: START\n",
      "Data Augmentation: END!\n"
     ]
    }
   ],
   "source": [
    "# Generate noisy signals from signal list\n",
    "print(\"Data Augmentation: START\")\n",
    "augmented_signal = list(map(noisy_signal, signal))\n",
    "print(\"Data Augmentation: END!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:48.306161Z",
     "start_time": "2019-05-21T16:31:48.011831Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[43mrandom_signal\u001b[49m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(sample_rate), random_signal)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim((np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(random_signal))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(sample_rate))[\u001b[38;5;241m0\u001b[39m], (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(random_signal))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(sample_rate))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime (s)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_signal' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot signal wave\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(len(random_signal))/float(sample_rate), random_signal)\n",
    "plt.xlim((np.arange(len(random_signal))/float(sample_rate))[0], (np.arange(len(random_signal))/float(sample_rate))[-1])\n",
    "plt.xlabel('Time (s)', fontsize=16)\n",
    "plt.ylabel('Amplitude (dB)', fontsize=16)\n",
    "plt.title(\"Signal wave of file '{}' \".format(random_filename), fontsize=18)\n",
    "\n",
    "# Plot signal wave with noise\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(len(random_signal))/float(sample_rate), augmented_signal[random_idx][0])\n",
    "plt.xlim((np.arange(len(random_signal))/float(sample_rate))[0], (np.arange(len(random_signal))/float(sample_rate))[-1])\n",
    "plt.xlabel('Time (s)', fontsize=16)\n",
    "plt.ylabel('Amplitude (dB)', fontsize=16)\n",
    "plt.title(\"Signal wave of file '{}' with Noise\".format(random_filename), fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# Play audio file\n",
    "print(\"Audio file '{}':\".format(random_filename))\n",
    "IPython.display.display(Audio(random_signal, rate=sample_rate))\n",
    "\n",
    "# Play same audio file with noise\n",
    "print(\"Audio file '{}' with noise:\".format(random_filename))\n",
    "IPython.display.display(Audio(augmented_signal[random_idx][0], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T17:10:51.478413Z",
     "start_time": "2018-12-04T17:10:51.475113Z"
    }
   },
   "source": [
    "## VI. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:48.312940Z",
     "start_time": "2019-05-21T16:31:48.308691Z"
    }
   },
   "outputs": [],
   "source": [
    "def mel_spectrogram(y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
    "    \n",
    "    # Compute spectogram\n",
    "    mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
    "    \n",
    "    # Compute mel spectrogram\n",
    "    mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    \n",
    "    # Compute log-mel spectrogram\n",
    "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "    \n",
    "    return mel_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:06.530587Z",
     "start_time": "2019-05-21T16:31:48.314692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction: START\n",
      "Feature extraction: END!\n"
     ]
    }
   ],
   "source": [
    "# Start feature extraction\n",
    "print(\"Feature extraction: START\")\n",
    "\n",
    "# Compute spectogram for all audio file\n",
    "mel_spect = np.asarray(list(map(mel_spectrogram, signal)))\n",
    "augmented_mel_spect = [np.asarray(list(map(mel_spectrogram, augmented_signal[i]))) for i in range(len(augmented_signal))]\n",
    "\n",
    "# Stop feature extraction\n",
    "print(\"Feature extraction: END!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:06.872643Z",
     "start_time": "2019-05-21T16:32:06.533176Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot one random Spectogram \u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(mel_spect[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmel_spect\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m], origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLog-Mel Spectrogram of an audio file\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m26\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "File \u001b[0;32mmtrand.pyx:748\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1247\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot one random Spectogram \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(mel_spect[np.random.randint(len(mel_spect))], origin='lower', aspect='auto', cmap='viridis')\n",
    "plt.title('Log-Mel Spectrogram of an audio file', fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:09.304749Z",
     "start_time": "2019-05-21T16:32:06.874812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build Train and test dataset\n",
    "MEL_SPECT_train, MEL_SPECT_test, AUG_MEL_SPECT_train, AUG_MEL_SPECT_test, label_train, label_test = train_test_split(mel_spect, augmented_mel_spect, labels, test_size=0.2)\n",
    "\n",
    "# Build augmented labels and train\n",
    "aug_label_train = np.asarray(list(itertools.chain.from_iterable([[label] * nb_augmented for label in label_train])))\n",
    "AUG_MEL_SPECT_train = np.asarray(list(itertools.chain.from_iterable(AUG_MEL_SPECT_train)))\n",
    "\n",
    "# Concatenate original and augmented\n",
    "X_train = np.concatenate((MEL_SPECT_train, AUG_MEL_SPECT_train))\n",
    "y_train = np.concatenate((label_train, aug_label_train))\n",
    "\n",
    "# Build test set\n",
    "X_test = MEL_SPECT_test\n",
    "y_test = label_test\n",
    "\n",
    "# Delete\n",
    "del MEL_SPECT_train, AUG_MEL_SPECT_train, label_train, aug_label_train, AUG_MEL_SPECT_test, MEL_SPECT_test, label_test\n",
    "del mel_spect, augmented_mel_spect, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Time distributed framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:13.861389Z",
     "start_time": "2019-05-21T16:32:09.306396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time distributed parameters\n",
    "win_ts = 128\n",
    "hop_ts = 64\n",
    "\n",
    "# Split spectrogram into frames\n",
    "def frame(x, win_step=128, win_size=64):\n",
    "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
    "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
    "    for t in range(nb_frames):\n",
    "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
    "    return frames\n",
    "\n",
    "# Frame for TimeDistributed model\n",
    "X_train = frame(X_train, hop_ts, win_ts)\n",
    "X_test = frame(X_test, hop_ts, win_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Save as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:16.173921Z",
     "start_time": "2019-05-21T16:32:13.863202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Train and test set\n",
    "pickle.dump(X_train.astype(np.float16), open('../Datas/Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][X_train].p', 'wb'))\n",
    "pickle.dump(y_train, open('../Datas/Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][y_train].p', 'wb'))\n",
    "pickle.dump(X_test.astype(np.float16), open('../Datas/Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][X_test].p', 'wb'))\n",
    "pickle.dump(y_test, open('../Datas/Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][y_test].p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
